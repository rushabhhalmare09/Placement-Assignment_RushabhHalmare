{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Question - 1\n",
        "Take any YouTube videos link and your task is to extract the comments from\n",
        "that videos and store it in a csv file and then you need define what is most\n",
        "demanding topic in that videos comment section."
      ],
      "metadata": {
        "id": "McdWZZa3y_Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Set up the YouTube Data API client\n",
        "api_key = 'AIzaSyApcfksYOFDDngUy5VZkPiNblMAmPucSAE'\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "# Specify the video ID or URL of the YouTube video you want to extract comments from\n",
        "video_id = 'VeodJ4XwoSE'\n",
        "\n",
        "# Retrieve comments from the YouTube video\n",
        "comments = []\n",
        "next_page_token = None\n",
        "while True:\n",
        "    response = youtube.commentThreads().list(\n",
        "        part='snippet',\n",
        "        videoId=video_id,\n",
        "        pageToken=next_page_token,\n",
        "        maxResults=100\n",
        "    ).execute()\n",
        "\n",
        "    for item in response['items']:\n",
        "        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "        comments.append(comment)\n",
        "\n",
        "    next_page_token = response.get('nextPageToken')\n",
        "    if not next_page_token:\n",
        "        break\n",
        "\n",
        "# Save the comments to a CSV file\n",
        "with open('comment.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Comment'])\n",
        "    writer.writerows([[comment] for comment in comments])\n",
        "\n",
        "print(\"Comment Extraction Completed, comment.csv file is created\\n\")\n",
        "\n",
        "# Analyze the comments to determine the most demanding topic\n",
        "# Choose the one that suits your requirements and use the comments stored in the 'comments' list\n",
        "\n",
        "# Example: Count the frequency of words in the comments\n",
        "word_freq = {}\n",
        "for comment in comments:\n",
        "    words = comment.split()\n",
        "    for word in words:\n",
        "        word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "# Find the most frequent word\n",
        "most_demanding_topic = max(word_freq, key=word_freq.get)\n",
        "print('most frequent used word:', most_demanding_topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi_yx-B_0Yn1",
        "outputId": "2ed77dd3-79e0-4d18-954e-c977e0c7d566"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment Extraction Completed, comment.csv file is created\n",
            "\n",
            "most frequent used word: a\n"
          ]
        }
      ]
    }
  ]
}